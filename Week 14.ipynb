{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS 3 - Week 14 - Multivariate Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Voting for the ACA and 2010 Vote Share as Difference of Means/Regression\n",
    "We are going to return to the example of the Affordable Care Act, and look at the political implications of the bill. Recall that the Democrats lost 63 seats in the House in the 2010 midterms after the passing of the ACA. Let's explore if there is evidence that this was driven by votes on the bill.\n",
    "\n",
    "First, we are going to load up some data on these house elections. The data come from <a href=\"https://journals.sagepub.com/doi/abs/10.1177/1532673X11433768\">this paper</a>, and are stored in Stata format. We can read this in using the `read_stata` function from the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcr_mid = pd.read_stata(\"hcr_midterm.dta\")\n",
    "hcr_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How someone voted on the ACA is stored in the variable `hcr_yes`, and their whether they are a Republican or Democrat is in `party`. Let's look at the relationship between these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(hcr_mid[\"hcr_yes\"], hcr_mid[\"party\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only <a href=\"https://en.wikipedia.org/wiki/Joseph_Cao\">one Republican</a> voted for the bill, and 39 democrats voted against it. The main comparison we want to make is whether the Democrats who voted for the bill did better or worse in the 2010 midterms than those who voted against it.\n",
    "\n",
    "To do this, let's first subset the data to districts with democratic incumbents who ran in competitive elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcr_mid = hcr_mid[(hcr_mid[\"dem_n\"] > 0) & (hcr_mid[\"party\"]==\"D\")]\n",
    "hcr_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dem_n` variable is the democratic vote share in the 2010 midterms. Let's look at the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(hcr_mid[\"dem_n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(hcr_mid[\"dem_n\"])\n",
    "plt.axvline(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average D running for re-election recieved almos 60% of the vote, but quite a few lost re-election.\n",
    "\n",
    "Now let's compare the performance of those who voted for and against the bill. First, let's create separate data files for the Y and N voters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcr_mid_y = hcr_mid[hcr_mid[\"hcr_yes\"] == 1]\n",
    "hcr_mid_n = hcr_mid[hcr_mid[\"hcr_yes\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And take the averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_y = np.mean(hcr_mid_y[\"dem_n\"])\n",
    "mean_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_n = np.mean(hcr_mid_n[\"dem_n\"])\n",
    "mean_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the raw difference of means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = mean_y - mean_n\n",
    "dom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates those who voted Y did about 13% better, which i a huge difference! Let's do a t-test to see if this is statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = stats.ttest_ind(hcr_mid_y[\"dem_n\"], hcr_mid_n[\"dem_n\"])\n",
    "t_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a t-statistic above 6, this is easily statistically significant at the p < .01 level.\n",
    "\n",
    "As discussed in the lecture, we can also test this with a bivariate regression where our IV is the vote and the DV is the vote share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = stats.linregress(hcr_mid[\"hcr_yes\"], hcr_mid[\"dem_n\"])\n",
    "ols_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"slope\" is equal to the difference of means, and the intercept is the mean of those who voted N. (Why?) Note we also get the same p value as the difference of means test. We can also check the t value is the same by dividing the slope by the standard error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model[0]/ols_model[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Adding District Liberalness\n",
    "Now let's think about some reasons why this relationship might not be causal. A major confounding variable is that those who voted Yes likely represent more liberal districts, making their re-election easier. To check this, we will look also bring Obama's 2008 vote share into our analysis.\n",
    "\n",
    "First, let's look at the relationship between Obama's 2008 vote share and the House members 2010 vote share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a strong positive relationship. This shouldn't surprise us: most people vote for the same party consistently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='obama', y='hcr_yes', data=hcr_mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a little goofy because the hcr_yes variable just takes on value of 0 or 1. We can still run a \"linear probability model\" with Obama vote share as the independent ($X$) variable and the vote as the dependent ($Y$) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_model = stats.linregress(hcr_mid[\"obama\"], hcr_mid[\"hcr_yes\"])\n",
    "vote_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the DV here is binary, we can interpret the slope as meaning \"as Obama vote share goes up by 1%, the probability of voting for the ACA increases by 1.4%.\n",
    "\n",
    "We can plot this prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='obama', y='hcr_yes', data=hcr_mid)\n",
    "xrange = np.arange(30, 100)\n",
    "plt.plot(xrange, vote_model[1] + xrange*vote_model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to plot this is by looking at the what proportion of D's voted yes for \"bins\". The red dots plot out the proportion who voted for the ACA among those in districts where Obama got 30%-39%, 40%-49%, 50%-59%, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcr_mid[\"obama_group\"] = 10*np.floor(hcr_mid[\"obama\"]/10)\n",
    "plt.plot(hcr_mid.groupby([\"obama_group\"]).mean()[\"hcr_yes\"], \"ro\")\n",
    "plt.plot(xrange, vote_model[1] + xrange*vote_model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may not be the best way to model the relationship, but it is certainly positive. See Chapter 12 of K&W for more informationa about alternative approxaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis\n",
    "Now visualize the three variable together, but doing a scatter plot of Obama vote share and 2010 Democratic vote share, with green dots for those who voted Y and orange dots for those who voted N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_y, color=\"green\")\n",
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_n, color=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the orange dots are to the left, meaning those who voted N where generally in more moderate/conservative districts.\n",
    "\n",
    "We can visualize the difference in average vote share by adding horizontal lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_y, color=\"green\")\n",
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_n, color=\"orange\")\n",
    "plt.axhline(mean_y, color='green')\n",
    "plt.axhline(mean_n, color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at the relationship between the vote and how liberal the district was by plotting the average Obama vote share among the Y and N districts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_y, color=\"green\")\n",
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_n, color=\"orange\")\n",
    "plt.axvline(np.mean(hcr_mid_y[\"obama\"]), color='green')\n",
    "plt.axvline(np.mean(hcr_mid_n[\"obama\"]), color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining what we know so far: districts where members voted Y did much better in the election, but these were also just more liberal (\"safe\") disticts. \n",
    "\n",
    "Now lets use mulitvariate regression to \"control\" for Obama vote share.\n",
    "\n",
    "First, let's re-do our bivariate analysis using the `OLS` function from the statsmodels.formula.api library, which is a nice libray for multivariate regression. (As a side note, it mimics the syntax of regression from R.) \n",
    "\n",
    "We will do this in two steps. In the first, we \"fit a model\" using `modelname = smf.ols(formula, data=df).fit()`. The formula will always take the form DV = IV1 + IV2 + ..., using the names of the variables in `df`. \n",
    "\n",
    "We then get a summary of the output by using the `.summary()` function on our fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_biv = smf.ols('dem_n ~ hcr_yes', data=hcr_mid).fit()\n",
    "ols_biv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same, adding the Obama vote share. The code is the same but we add `+ obama` to the formula to indicate we should include this variable too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_biv = smf.ols('dem_n ~ hcr_yes + obama', data=hcr_mid).fit()\n",
    "ols_biv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is a negative coefficient on `hcr_yes`!\n",
    "\n",
    "To make a plot, we can pull out the coefficients by adding a `.params` after the name of our fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_biv.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the predicted value for Y and N votes as a function of Obama vote share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_y, color=\"green\")\n",
    "sns.scatterplot(x='obama', y='dem_n', data=hcr_mid_n, color=\"orange\")\n",
    "xrange = np.arange(30, 100)\n",
    "plt.plot(xrange, ols_biv.params[0] + xrange*ols_biv.params[2], color=\"orange\")\n",
    "plt.plot(xrange, ols_biv.params[0] + ols_biv.params[1] + xrange*ols_biv.params[2], color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice illustration of what we mean by \"controlling for Obama vote share\" or \"holding Obama vote share constant\". The model accounts for both of these variables, and so the prediction is that *for a fixed level of Obama vote share*, those who vote N do 4.5% better. Visually, there are two parallel lines, and the N line is always 4.5% higher. \n",
    "\n",
    "Knowing the Obama vote share for each Democrat in the house, the model does not predict that those who vote N will do better in general, because they tend to be in more conservative districts. But it does predict for any two members in districts where Obama got the same vote share, but one votes Y and one votes N, the one voting N will do 4.5% better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The takeaway is that the main drive of how well D's running did in 2010 is how well Obama did in 2008. The fact that those who voted for the ACA did better overall is hence misleading!\n",
    "\n",
    "This model predicts that in a counterfactual world those who voted against the ACA would have done about 4.5% worse in their re-elction bids. Conversely, those who voted for it could have done better (and some likely would have been re-elected) if they voted against it. \n",
    "\n",
    "Some important caveats:\n",
    "- This may not be the \"right\" model: there might be remaining confounding variables.\n",
    "- We are implicitly assumign that the effect of voting for the ACA is the same for everyone, which is probably not true: in very liberal disticts voters probably would have been unappy in their representative voted no!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Variables\n",
    "\n",
    "To get a bit more practice with multivariate regression and how to interpret regression with ordinal variables, we will do some quick analysis with the National Election Study of 2004 (in the United States). This is a major survey of Americans and their political attitudes.\n",
    "\n",
    "<a href='https://berkeley.app.box.com/file/745549999463'>Here is a codebook</a> with some detail about the variables. In short, the main variables we will look at are:\n",
    "- `bush_therm`, which is how much people like George W Bush on a scale from 0 to 100\n",
    "- `education`, an ordinal variable ranging from 1 (8 grades or less) to 7 (Advanced degree)\n",
    "- `income`, an ordinal variable ranging from 1 (none or less than 2999) to 23 (120,000 and over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religion</th>\n",
       "      <th>bush</th>\n",
       "      <th>female</th>\n",
       "      <th>unionhouse</th>\n",
       "      <th>partyid</th>\n",
       "      <th>eval_WoT</th>\n",
       "      <th>eval_HoE</th>\n",
       "      <th>ideology</th>\n",
       "      <th>bush_therm</th>\n",
       "      <th>education</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1212 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      religion  bush  female  unionhouse  partyid  eval_WoT  eval_HoE  \\\n",
       "0          7.0   0.0     0.0         1.0      3.0       NaN       0.0   \n",
       "1          1.0   0.0     0.0         0.0      2.0      -1.0      -1.0   \n",
       "2          1.0   1.0     1.0         0.0      6.0       2.0       2.0   \n",
       "3          1.0   NaN     0.0         0.0      3.0      -2.0      -1.0   \n",
       "4          1.0   1.0     1.0         0.0      6.0       2.0       2.0   \n",
       "...        ...   ...     ...         ...      ...       ...       ...   \n",
       "1207       1.0   1.0     1.0         0.0      5.0       2.0       NaN   \n",
       "1208       1.0   NaN     1.0         0.0      5.0       2.0       1.0   \n",
       "1209       2.0   1.0     0.0         1.0      6.0       2.0       1.0   \n",
       "1210       2.0   NaN     1.0         1.0      1.0       2.0      -1.0   \n",
       "1211       1.0   NaN     0.0         0.0      4.0       2.0       1.0   \n",
       "\n",
       "      ideology  bush_therm  education  income  \n",
       "0          4.0        70.0        7.0    17.0  \n",
       "1          4.0        40.0        4.0    19.0  \n",
       "2          6.0       100.0        6.0    23.0  \n",
       "3          4.0        50.0        2.0     3.0  \n",
       "4          6.0       100.0        3.0    12.0  \n",
       "...        ...         ...        ...     ...  \n",
       "1207       NaN       100.0        3.0     6.0  \n",
       "1208       7.0        70.0        4.0    13.0  \n",
       "1209       6.0        85.0        6.0    18.0  \n",
       "1210       4.0        70.0        5.0    20.0  \n",
       "1211       6.0        85.0        3.0     NaN  \n",
       "\n",
       "[1212 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nes = pd.read_stata(\"nes2004subset.dta\")\n",
    "nes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first look at the bivariate relationship between `education` and `bush_therm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>bush_therm</td>    <th>  R-squared:         </th> <td>   0.006</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.213</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Nov 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:39:55</td>     <th>  Log-Likelihood:    </th> <td> -5948.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1207</td>      <th>  AIC:               </th> <td>1.190e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1205</td>      <th>  BIC:               </th> <td>1.191e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   61.8608</td> <td>    2.751</td> <td>   22.490</td> <td> 0.000</td> <td>   56.464</td> <td>   67.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th> <td>   -1.6074</td> <td>    0.598</td> <td>   -2.686</td> <td> 0.007</td> <td>   -2.782</td> <td>   -0.433</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>719.143</td> <th>  Durbin-Watson:     </th> <td>   1.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  84.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.286</td>  <th>  Prob(JB):          </th> <td>3.93e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.834</td>  <th>  Cond. No.          </th> <td>    13.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             bush_therm   R-squared:                       0.006\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     7.213\n",
       "Date:                Tue, 24 Nov 2020   Prob (F-statistic):            0.00734\n",
       "Time:                        12:39:55   Log-Likelihood:                -5948.7\n",
       "No. Observations:                1207   AIC:                         1.190e+04\n",
       "Df Residuals:                    1205   BIC:                         1.191e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     61.8608      2.751     22.490      0.000      56.464      67.257\n",
       "education     -1.6074      0.598     -2.686      0.007      -2.782      -0.433\n",
       "==============================================================================\n",
       "Omnibus:                      719.143   Durbin-Watson:                   1.958\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               84.762\n",
       "Skew:                          -0.286   Prob(JB):                     3.93e-19\n",
       "Kurtosis:                       1.834   Cond. No.                         13.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idmodel_biv1 = smf.ols('bush_therm ~ education', data=nes).fit()\n",
    "idmodel_biv1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that going up by one education category (e.g., \"high school degree\" to \"some college\" or \"completed college\" to \"advanced degree\") or is associated with liking Bush less by 1.6 points on the 100 point scale. This isn't a huge effect, but it is highly statisticaly significant.\n",
    "\n",
    "Now let's doe the same thing for income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>bush_therm</td>    <th>  R-squared:         </th> <td>   0.008</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.305</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Nov 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00403</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:41:16</td>     <th>  Log-Likelihood:    </th> <td> -5258.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1066</td>      <th>  AIC:               </th> <td>1.052e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1064</td>      <th>  BIC:               </th> <td>1.053e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   46.9584</td> <td>    2.773</td> <td>   16.932</td> <td> 0.000</td> <td>   41.516</td> <td>   52.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td>    0.4959</td> <td>    0.172</td> <td>    2.882</td> <td> 0.004</td> <td>    0.158</td> <td>    0.834</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>638.066</td> <th>  Durbin-Watson:     </th> <td>   1.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  76.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.296</td>  <th>  Prob(JB):          </th> <td>2.85e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.832</td>  <th>  Cond. No.          </th> <td>    43.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             bush_therm   R-squared:                       0.008\n",
       "Model:                            OLS   Adj. R-squared:                  0.007\n",
       "Method:                 Least Squares   F-statistic:                     8.305\n",
       "Date:                Tue, 24 Nov 2020   Prob (F-statistic):            0.00403\n",
       "Time:                        12:41:16   Log-Likelihood:                -5258.4\n",
       "No. Observations:                1066   AIC:                         1.052e+04\n",
       "Df Residuals:                    1064   BIC:                         1.053e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     46.9584      2.773     16.932      0.000      41.516      52.400\n",
       "income         0.4959      0.172      2.882      0.004       0.158       0.834\n",
       "==============================================================================\n",
       "Omnibus:                      638.066   Durbin-Watson:                   1.908\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               76.193\n",
       "Skew:                          -0.296   Prob(JB):                     2.85e-17\n",
       "Kurtosis:                       1.832   Cond. No.                         43.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idmodel_biv2 = smf.ols('bush_therm ~ income', data=nes).fit()\n",
    "idmodel_biv2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going up by 1 income category (e.g., 17,000-19,999 to 20,000-21,999 or  60,000-74,999 to 75,000-89,999) is associated with liking Bush more by half a point.\n",
    "\n",
    "Note that income and education are also going to be positively correlated. So, when looking at an increase in education, we are probably capturing the effect of getting educated by increasing income and through other channels. Similalr, by comparing people in different income categories, we are also looking at different levels of education.\n",
    "\n",
    "Now let's run a multivariate regression with both of these factors, which will allow us to anser \"keeping income fixed, what is the relationship betweeen education and liking Bush\", and \"keeping education fixed, what is the relationship between income and liking Bush?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>bush_therm</td>    <th>  R-squared:         </th> <td>   0.027</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.025</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>6.26e-07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:42:34</td>     <th>  Log-Likelihood:    </th> <td> -5248.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1066</td>      <th>  AIC:               </th> <td>1.050e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1063</td>      <th>  BIC:               </th> <td>1.052e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   55.3680</td> <td>    3.317</td> <td>   16.691</td> <td> 0.000</td> <td>   48.859</td> <td>   61.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th> <td>   -3.2054</td> <td>    0.708</td> <td>   -4.527</td> <td> 0.000</td> <td>   -4.595</td> <td>   -1.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td>    0.8699</td> <td>    0.189</td> <td>    4.591</td> <td> 0.000</td> <td>    0.498</td> <td>    1.242</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>500.403</td> <th>  Durbin-Watson:     </th> <td>   1.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  69.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.262</td>  <th>  Prob(JB):          </th> <td>9.34e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.867</td>  <th>  Cond. No.          </th> <td>    54.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             bush_therm   R-squared:                       0.027\n",
       "Model:                            OLS   Adj. R-squared:                  0.025\n",
       "Method:                 Least Squares   F-statistic:                     14.48\n",
       "Date:                Tue, 24 Nov 2020   Prob (F-statistic):           6.26e-07\n",
       "Time:                        12:42:34   Log-Likelihood:                -5248.2\n",
       "No. Observations:                1066   AIC:                         1.050e+04\n",
       "Df Residuals:                    1063   BIC:                         1.052e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     55.3680      3.317     16.691      0.000      48.859      61.877\n",
       "education     -3.2054      0.708     -4.527      0.000      -4.595      -1.816\n",
       "income         0.8699      0.189      4.591      0.000       0.498       1.242\n",
       "==============================================================================\n",
       "Omnibus:                      500.403   Durbin-Watson:                   1.902\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               69.215\n",
       "Skew:                          -0.262   Prob(JB):                     9.34e-16\n",
       "Kurtosis:                       1.867   Cond. No.                         54.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idmodel_multi1 = smf.ols('bush_therm ~ education + income', data=nes).fit()\n",
    "idmodel_multi1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the relationships become *stronger* here. This shouldn't surprise us, since they are positively correlated with each other but have opposite correlations with liking Bush. \n",
    "\n",
    "So, it seems that, for a fixed income level, people with more education like Bush a fair amount less. However, without controlling for income, some of this relationship gets masked because better educated people are also more wealthy, and wealthy people tend to like Bush.\n",
    "\n",
    "Similarly, for a fixed level of education, people with more income like Bush a fair amount more. However, without controlling for education, some of this relationship gets masked because richer people tend to be better educated.\n",
    "\n",
    "We can also control for lots of other variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>bush_therm</td>    <th>  R-squared:         </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   96.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>5.17e-67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:46:57</td>     <th>  Log-Likelihood:    </th> <td> -3931.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   825</td>      <th>  AIC:               </th> <td>   7872.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   820</td>      <th>  BIC:               </th> <td>   7896.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    3.8839</td> <td>    4.641</td> <td>    0.837</td> <td> 0.403</td> <td>   -5.226</td> <td>   12.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th> <td>   -1.5650</td> <td>    0.686</td> <td>   -2.280</td> <td> 0.023</td> <td>   -2.912</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td>    0.2925</td> <td>    0.190</td> <td>    1.543</td> <td> 0.123</td> <td>   -0.080</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>    <td>   -0.6110</td> <td>    2.007</td> <td>   -0.305</td> <td> 0.761</td> <td>   -4.550</td> <td>    3.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ideology</th>  <td>   12.6849</td> <td>    0.680</td> <td>   18.641</td> <td> 0.000</td> <td>   11.349</td> <td>   14.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.679</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  15.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.332</td> <th>  Prob(JB):          </th> <td>0.000494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.948</td> <th>  Cond. No.          </th> <td>    84.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             bush_therm   R-squared:                       0.319\n",
       "Model:                            OLS   Adj. R-squared:                  0.316\n",
       "Method:                 Least Squares   F-statistic:                     96.02\n",
       "Date:                Tue, 24 Nov 2020   Prob (F-statistic):           5.17e-67\n",
       "Time:                        12:46:57   Log-Likelihood:                -3931.1\n",
       "No. Observations:                 825   AIC:                             7872.\n",
       "Df Residuals:                     820   BIC:                             7896.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.8839      4.641      0.837      0.403      -5.226      12.994\n",
       "education     -1.5650      0.686     -2.280      0.023      -2.912      -0.218\n",
       "income         0.2925      0.190      1.543      0.123      -0.080       0.665\n",
       "female        -0.6110      2.007     -0.305      0.761      -4.550       3.328\n",
       "ideology      12.6849      0.680     18.641      0.000      11.349      14.021\n",
       "==============================================================================\n",
       "Omnibus:                       14.679   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.225\n",
       "Skew:                          -0.332   Prob(JB):                     0.000494\n",
       "Kurtosis:                       2.948   Cond. No.                         84.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idmodel_multi1 = smf.ols('bush_therm ~ education + income + female + ideology', data=nes).fit()\n",
    "idmodel_multi1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting observation here is that there is no statistically significant relationship between gender and liking Bush. (I suspect this would not be true of more recent Republican presidents!)\n",
    "\n",
    "Note the ideology variable (measured on a 7 point scale) has a large coefficient which is highly statistically significant. This shouldn't surprise us: more conservative people like Bush better.\n",
    "\n",
    "Note that oru coefficients for education and income go down once we control for ideology. One reason that people with more income like Bush more is that people with more income tend to like Bush more. So, controlling for ideology says \"keeping ideology (and other factors) fixed, how is income associated with liking Bush\". But if we want to see the total effect of income on liking Bush, we might not want to control for ideology. We won't have time to get into the details here, but this issue is called <a href=\"https://catalogofbias.org/biases/collider-bias/#:~:text=The%20collider%20bias%20occurs%20when,effect%20of%20obesity%20on%20mortality.\">collider bias</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
